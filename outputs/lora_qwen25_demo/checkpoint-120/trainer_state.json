{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.7317073170731705,
  "eval_steps": 500,
  "global_step": 120,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.24390243902439024,
      "grad_norm": 1.5620813369750977,
      "learning_rate": 0.00019333333333333333,
      "loss": 1.6703,
      "step": 5
    },
    {
      "epoch": 0.4878048780487805,
      "grad_norm": 1.4909324645996094,
      "learning_rate": 0.00018500000000000002,
      "loss": 1.2548,
      "step": 10
    },
    {
      "epoch": 0.7317073170731707,
      "grad_norm": 1.0529438257217407,
      "learning_rate": 0.00017666666666666666,
      "loss": 1.0022,
      "step": 15
    },
    {
      "epoch": 0.975609756097561,
      "grad_norm": 1.178581953048706,
      "learning_rate": 0.00016833333333333335,
      "loss": 0.8278,
      "step": 20
    },
    {
      "epoch": 1.1951219512195121,
      "grad_norm": 1.1472479104995728,
      "learning_rate": 0.00016,
      "loss": 0.7257,
      "step": 25
    },
    {
      "epoch": 1.4390243902439024,
      "grad_norm": 1.1189137697219849,
      "learning_rate": 0.00015166666666666668,
      "loss": 0.5124,
      "step": 30
    },
    {
      "epoch": 1.6829268292682928,
      "grad_norm": 0.9036943912506104,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.4809,
      "step": 35
    },
    {
      "epoch": 1.9268292682926829,
      "grad_norm": 0.8252786993980408,
      "learning_rate": 0.00013500000000000003,
      "loss": 0.4533,
      "step": 40
    },
    {
      "epoch": 2.1463414634146343,
      "grad_norm": 0.6775914430618286,
      "learning_rate": 0.00012666666666666666,
      "loss": 0.4089,
      "step": 45
    },
    {
      "epoch": 2.3902439024390243,
      "grad_norm": 0.7705241441726685,
      "learning_rate": 0.00011833333333333334,
      "loss": 0.3888,
      "step": 50
    },
    {
      "epoch": 2.6341463414634148,
      "grad_norm": 0.8271408081054688,
      "learning_rate": 0.00011000000000000002,
      "loss": 0.4103,
      "step": 55
    },
    {
      "epoch": 2.8780487804878048,
      "grad_norm": 0.9574342966079712,
      "learning_rate": 0.00010166666666666667,
      "loss": 0.3896,
      "step": 60
    },
    {
      "epoch": 3.097560975609756,
      "grad_norm": 0.8888916373252869,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.3322,
      "step": 65
    },
    {
      "epoch": 3.341463414634146,
      "grad_norm": 0.8075557351112366,
      "learning_rate": 8.5e-05,
      "loss": 0.3133,
      "step": 70
    },
    {
      "epoch": 3.5853658536585367,
      "grad_norm": 0.7795612215995789,
      "learning_rate": 7.666666666666667e-05,
      "loss": 0.3272,
      "step": 75
    },
    {
      "epoch": 3.8292682926829267,
      "grad_norm": 0.6345650553703308,
      "learning_rate": 6.833333333333333e-05,
      "loss": 0.3339,
      "step": 80
    },
    {
      "epoch": 4.048780487804878,
      "grad_norm": 0.5915133953094482,
      "learning_rate": 6e-05,
      "loss": 0.2375,
      "step": 85
    },
    {
      "epoch": 4.2926829268292686,
      "grad_norm": 0.6713336110115051,
      "learning_rate": 5.166666666666667e-05,
      "loss": 0.2406,
      "step": 90
    },
    {
      "epoch": 4.536585365853659,
      "grad_norm": 0.6600167155265808,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.2716,
      "step": 95
    },
    {
      "epoch": 4.780487804878049,
      "grad_norm": 1.3724178075790405,
      "learning_rate": 3.5e-05,
      "loss": 0.2901,
      "step": 100
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.9878548979759216,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.2657,
      "step": 105
    },
    {
      "epoch": 5.2439024390243905,
      "grad_norm": 0.5717215538024902,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.2093,
      "step": 110
    },
    {
      "epoch": 5.487804878048781,
      "grad_norm": 0.6597326993942261,
      "learning_rate": 1e-05,
      "loss": 0.2374,
      "step": 115
    },
    {
      "epoch": 5.7317073170731705,
      "grad_norm": 0.5543022155761719,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.2395,
      "step": 120
    }
  ],
  "logging_steps": 5,
  "max_steps": 120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 529450814668800.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

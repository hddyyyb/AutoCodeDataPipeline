# Dataset Schema Definition

## 1. Purpose

This document defines the unified dataset schema used in AutoCodeDataPipeline
for generating training data from a local code repository.

The dataset is designed to support:
- QA-style instruction tuning for code understanding and rule explanation
- Architecture-level design tasks grounded in an existing codebase

All samples are generated automatically and include explicit code grounding
and auditable reasoning traces.

---

## 2. Dataset Overview

The dataset is stored in JSONL format, where each line represents one training sample.

Each sample contains a common set of high-level fields:
- sample_id
- task_type (qa or design)
- language
- evidence
- trace
- meta

Two task types are supported:
- QA: code-grounded question answering
- Design: architecture and system design based on repository constraints

---

## 3. QA Sample Schema

### 3.1 Fields

| Field | Type | Description |
|------|------|-------------|
| sample_id | string | Unique identifier of the sample |
| task_type | string | Fixed value: "qa" |
| language | string | Language of the question/answer (e.g., zh, en) |
| question | string | Natural language question derived from business rules or flows |
| answer | string | Grounded answer based on referenced code |
| evidence | list | List of code evidence blocks |
| trace | object | Auditable reasoning trace |
| meta | object | Metadata for analysis and governance |

### 3.2 Evidence Object

Each evidence item contains:

| Field | Type | Description |
|------|------|-------------|
| chunk_id | string | Identifier from repo_index |
| file_path | string | Source code file path |
| start_line | int | Start line number |
| end_line | int | End line number |
| content | string | Code snippet |

At least one evidence block must reference a valid chunk_id
in the repository index.

### 3.3 Trace Object

The trace object captures a lightweight, auditable reasoning process:

```json
{
  "type": "rule_based",
  "reasoning_steps": [
    "Locate relevant business rule",
    "Inspect corresponding code block",
    "Summarize implementation logic"
  ]
}
```
The trace is not intended to expose model chain-of-thought,
but to provide human-readable auditability.

### 3.4 Meta Object

| Field | Description |
|------|-------------|
| domain | Business domain (e.g., order, stock) |
| qa_type | Question type (rule or flow) |
| difficulty | Relative difficulty level |
| generator | Generator version identifier |
| source | Data source identifier |

## 4. Design Sample Schema

### 4.1 Fields

| Field | Type | Description |
|------|------|-------------|
| sample_id | string | Unique identifier |
| task_type | string | Fixed value: "design" |
| language | string | Language of the design description |
| requirement | string | Design requirement |
| repo_context | string | Summary of existing repository constraints |
| design_output | object | Structured design proposal |
| evidence | list | Referenced code evidence |
| trace | object | Design reasoning trace |
| meta | object | Metadata |

### 4.2 Design Output Structure

The design_output field is a structured object containing:

- architecture_overview
- components
- apis
- data_model
- sequence_flows
- risk_and_mitigation


This structure enables consistent downstream processing
and evaluation.

## 5. Evidence and Trace Constraints
Each sample must contain at least one valid evidence block.

Evidence chunk_id must exist in repo_index.

QA samples require at least 2 reasoning steps.

Design samples require at least 3 reasoning steps.

These constraints are enforced during post-processing and validation.

## 6. Multilingual Support and Extensibility
The schema is language-agnostic.
All language-specific variations are isolated in the generation templates.

By switching templates, the same schema can support:

Monolingual datasets

Bilingual or multilingual datasets

Cross-lingual instruction tuning

New task types or additional metadata fields
can be introduced without breaking existing samples.


## Appendix A: domain_map.json Structure (Intermediate Representation)

repo: { repo_path, generated_at, source_index }

boundaries: { controller, service, mapper, model, config, other }
Each field is a list of chunk_id values.

entities:
[
{ name, domain, confidence, evidence_chunks, mentions }
]

operations:
[
{ name, domain, confidence, evidence_chunks, signals }
]

candidate_flows:
[
{
flow_id,
name,
domain,
steps: [
{ idx, operation, evidence_chunk, why }
],
evidence_chunks
}
]
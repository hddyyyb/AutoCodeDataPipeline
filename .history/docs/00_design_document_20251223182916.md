# System Design Overview

This document describes the overall design of AutoCodeDataPipeline, focusing on **traceability, auditability, and training–inference alignment**.

---

## 1. Design Goals

- Automatically generate high-quality training data from a local code repository
- Ensure every sample is **fully grounded in source code**
- Provide **auditable reasoning traces** instead of opaque model reasoning
- Guarantee consistency between training data and inference-time constraints

---

## 2. Key Design Decisions

### 2.1 Chunk-Level Grounding

All downstream artifacts reference `chunk_id` generated in Step01.  
This ensures:
- Stable references across dataset iterations
- Precise trace-back to source code

---

### 2.2 Heuristic but Auditable Inference

Domain, entity, and flow inference rely on heuristics rather than full call graphs.

This is intentional:
- Completeness is sacrificed in favor of explainability
- Every inferred structure retains explicit evidence chunks

---

## 3. Data Generation Philosophy

- QA samples explain **how rules and flows are implemented**
- Design samples propose **architecture extensions constrained by existing code**
- Both require evidence and structured reasoning

---

## 4. Reasoning Trace Design (Non-CoT, Auditable)

Reasoning traces are **not chain-of-thought**.

Instead:
- Traces are short, structured step lists (`trace_digest`)
- Each step is grounded in referenced evidence
- Minimum step counts are enforced:
  - QA ≥ 2 steps
  - Design ≥ 3 steps

These traces are intended for **human auditability**, not for exposing internal model reasoning.

---

## 5. Training–Inference Alignment

A core principle of the system is that **training data must be valid under inference-time rules**.

This is achieved by:
- Using the same strict templates in SFT preparation and inference
- Enforcing evidence whitelists and chunk_id validation
- Rejecting or repairing invalid model outputs during inference


# Dataset Schema Definition

## 1. Purpose

This document defines the unified dataset schema used in AutoCodeDataPipeline.

The schema supports:
- Repository-grounded QA instruction tuning
- Architecture-level design tasks
- Auditable reasoning and traceability

This schema directly corresponds to the assignment requirement of:
“Defining the training dataset structure, including QA format, metadata, code context, and reasoning traces.”

---

## 2. Design Goals

The dataset schema is designed with the following goals:

- **Groundedness**: every sample must be traceable to original repository code
- **Auditability**: answers and designs must expose structured, verifiable reasoning
- **Training–Inference Consistency**: data generated under this schema must remain valid under inference-time constraints
- **Extensibility**: new repositories, domains, and task types can be supported without schema changes

---

## 3. Common Structure

All samples are stored in JSONL format.

Common fields:
- sample_id
- task_type (qa / design)
- language
- text (training-ready)
- meta (grounding and audit metadata)

The `text` field is used directly for instruction fine-tuning, while the `meta` field preserves all grounding and audit information without polluting model inputs.

---

## 4. QA Sample Schema

Key fields:
- question
- answer
- evidence
- trace
- meta_v2

### Evidence

Each evidence item must reference a valid `chunk_id` from the repository index.

### Trace

The trace captures a **lightweight, auditable reasoning path**.

Important constraints:
- Minimum reasoning steps are enforced
- Each step must be grounded by evidence
- Free-form chain-of-thought is explicitly avoided

---

## 5. Design Sample Schema

Design samples include:
- requirement
- design_output (structured object)
- evidence_snippets (original code)
- trace_digest

Minimum reasoning depth is enforced to ensure explainability.

---

## 6. Evidence and Trace Constraints

- Each sample must contain at least one valid evidence block
- `evidence_snippets` must include original code
- QA: trace ≥ 2 steps
- Design: trace ≥ 3 steps

These constraints are enforced during post-processing and inference validation.

## 7. Diversity and Representativeness Guarantees

The dataset is not generated by random sampling. Instead, diversity and representativeness
are explicitly enforced at multiple stages of the pipeline.

### Diversity

Diversity is achieved through:
- Multiple task types:
  - QA for business rules
  - QA for business flows
  - Architecture-level design tasks
- Multiple semantic perspectives:
  - Domain logic
  - Architectural layering
  - Failure handling, idempotency, and consistency patterns
- Variant generation:
  - The same requirement may produce multiple design samples
  - Different strategy combinations and reasoning traces are used

This prevents template-based or single-pattern training data.

### Representativeness

Representativeness is ensured by:
- Domain-aware sampling (order / stock / mixed)
- Quota-based selection across:
  - Domains
  - Architectural strategies
  - Source files
  - Code chunks
- Stable chunk-level grounding using `chunk_id`

As a result, the dataset reflects the dominant business logic and architectural patterns
of the repository without being dominated by any single file or implementation detail.

## 8. Summary

This dataset schema defines a clear and enforceable contract between
repository source code, automatically generated training data,
and downstream fine-tuning and inference systems.

It ensures that all samples are logically correct, auditable,
and explicitly aligned with the original assignment requirements.


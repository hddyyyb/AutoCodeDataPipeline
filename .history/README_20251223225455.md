# AutoCodeDataPipeline: Repository-Grounded Training Data Generation

This project builds an automated pipeline that converts a local GitHub repository into
**auditable instruction-tuning data** for Qwen2.5-series fine-tuning.

It explicitly targets two interview scenarios:

1) Scenario1: Generate repository-grounded QA pairs about business rules/flows,
   with **original code evidence** and an **auditable reasoning trace**.
2) Scenario2: Given a requirement, generate an architecture-aware **design proposal grounded in repo structure**,
   with **evidence snippets** and a **reasoning trace**.

---

## Target Repository

- Repository: https://github.com/macrozheng/mall
- Scope: Order & Inventory domains
- Language: Java (Spring-based backend)

---


## What You Get (Deliverables)

- Repository index with stable `chunk_id` for every code snippet (Step01)
- Domain map (architectural boundaries, entities, operations, candidate flows) (Step02)
- Extracted business rules and flow skeletons (Step03)
- QA samples (Scenario1) with evidence snippets + trace (Step04)
- Design samples (Scenario2) with evidence snippets + trace (Step05)
- Post-processing governance: schema/grounding/trace validation + dedup + splits (Step06)
- SFT export: text/messages format, language split (zh/en) (Step08)
- Optional: LoRA fine-tune + strict inference-time validation (Step09/Step10)

Key design principle:
**Training–inference alignment**: training samples are valid under the same hard constraints applied at inference time.

---


## Quickstart

### 0) Prepare repository
Clone macrozheng/mall into `repo/mall` (or configure your own repo scope).

### 1) Run pipeline
```bash
python scripts/01_index_repo.py
python scripts/02_build_domain_map.py
python scripts/03_extract_rules_and_flows.py
python scripts/04_generate_qa.py
python scripts/05_generate_design_tasks.py
python scripts/06_postprocess_and_validate.py
python scripts/08_prepare_sft_data.py
```
### 2) Inspect outputs

- `data/raw_index/repo_index.jsonl` (chunked code index)
- `data/extracted/domain_map.json` (domain map)
- `data/dataset/final_{train,dev,test}.jsonl` (validated dataset)
- `data/sft/{split}_{lang}.jsonl` (SFT-ready)

### 3) Optional: fine-tune and validate inference
```bash
python scripts/09_lora_finetune.py
python scripts/10_infer_lora.py
```





## Design Principles

1. **Repository-grounded only**  
   All generated samples must be traceable to original source code chunks (`chunk_id`).

2. **Auditable reasoning (non-CoT)**  
   Reasoning traces are structured, bounded, and verifiable.  
   Free-form chain-of-thought is explicitly avoided.

3. **Training–Inference consistency**  
   The SFT data format is strictly aligned with inference-time hard checks, ensuring no format drift between training and deployment.

---

## Supported Scenarios

1. **Scenario 1: QA Generation**  
   Generate question–answer pairs based on business rules and execution flows, with:
   - Explicit code evidence
   - Structured reasoning traces
   - Strict traceability guarantees

2. **Scenario 2: Architecture & Design Tasks**  
   Generate repository-constrained design tasks that:
   - Respect existing layered architecture
   - Include code-grounded evidence
   - Provide auditable design reasoning

---

## End-to-End Pipeline Overview



```
Code Repository
↓
Repository Indexing
↓
Domain & Structural Inference
↓
Rule & Flow Abstraction
↓
QA / Design Task Generation
↓
Postprocess & Validation
↓
Metrics & Reports
↓
(Optional) Model Fine-tuning & Inference
```


Each stage produces explicit intermediate artifacts to ensure **full traceability and auditability**.

---

## Pipeline Steps

| Step | Script | Purpose |
|-----:|--------|---------|
| 01 | scripts/01_index_repo.py | Chunk-level repository indexing |
| 02 | scripts/02_build_domain_map.py | Domain, entity, operation, and flow inference |
| 03 | scripts/03_extract_rules_and_flows.py | Business rule & flow abstraction |
| 04 | scripts/04_generate_qa.py | QA generation with evidence & reasoning |
| 05 | scripts/05_generate_design_tasks.py | Repository-grounded design tasks |
| 06 | scripts/06_postprocess_and_validate.py | Validation, deduplication, statistics |
| 07 | scripts/07_metrics_report.py | Human-readable metrics report |
| 08 | scripts/08_prepare_sft_data.py | SFT data preparation (training-ready) |
| 09 | scripts/09_lora_finetune.py | Lightweight LoRA fine-tuning |
| 10 | scripts/10_infer_lora.py | Strict inference & hard validation |

Steps 08–10 demonstrate that the generated dataset is **directly usable under strict inference constraints**, not merely theoretically valid.

---

## Documentation Guide

| Document | Description |
|--------|-------------|
| docs/00_design_document.md | Overall system design and rationale |
| docs/01_dataset_schema.md | Unified dataset schema |
| docs/02_domain_map.md | Domain map construction |
| docs/03_pipeline_design.md | Authoritative pipeline design |
| docs/04_demo_and_results.md | Metrics and validation results |



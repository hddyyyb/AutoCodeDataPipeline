# AutoCodeDataPipeline

AutoCodeDataPipeline is an end-to-end engineering pipeline for generating **auditable, repository-grounded training data** from a local codebase.

The project is implemented as a response to the interview assignment:

> **Local Code Repository–Based Intelligent Training Data Generation and Processing**

The pipeline is designed not only to generate QA and design samples, but also to **prove that these samples are directly consumable by LLMs under strict inference constraints**.

---

## Target Repository

- Repository: https://github.com/macrozheng/mall
- Scope: Order & Inventory domains
- Language: Java (Spring-based backend)

The repository is treated as a local codebase and indexed without modifying the original source.

---

## Design Principles

1. **Repository-grounded only**  
   All generated samples must be traceable to original source code chunks (`chunk_id`).

2. **Auditable reasoning (non-CoT)**  
   Reasoning traces are structured, bounded, and verifiable.  
   Free-form chain-of-thought is explicitly avoided.

3. **Training–Inference consistency**  
   The SFT data format is strictly aligned with inference-time hard checks, ensuring no format drift between training and deployment.

---

## Supported Scenarios

1. **Scenario 1: QA Generation**  
   Generate question–answer pairs based on business rules and execution flows, with:
   - Explicit code evidence
   - Structured reasoning traces
   - Strict traceability guarantees

2. **Scenario 2: Architecture & Design Tasks**  
   Generate repository-constrained design tasks that:
   - Respect existing layered architecture
   - Include code-grounded evidence
   - Provide auditable design reasoning

---

## End-to-End Pipeline Overview



```
Code Repository
↓
Repository Indexing
↓
Domain & Structural Inference
↓
Rule & Flow Abstraction
↓
QA / Design Task Generation
↓
Postprocess & Validation
↓
Metrics & Reports
↓
(Optional) Model Fine-tuning & Inference
```


Each stage produces explicit intermediate artifacts to ensure **full traceability and auditability**.

---

## Pipeline Steps

| Step | Script | Purpose |
|-----:|--------|---------|
| 01 | scripts/01_index_repo.py | Chunk-level repository indexing |
| 02 | scripts/02_build_domain_map.py | Domain, entity, operation, and flow inference |
| 03 | scripts/03_extract_rules_and_flows.py | Business rule & flow abstraction |
| 04 | scripts/04_generate_qa.py | QA generation with evidence & reasoning |
| 05 | scripts/05_generate_design_tasks.py | Repository-grounded design tasks |
| 06 | scripts/06_postprocess_and_validate.py | Validation, deduplication, statistics |
| 07 | scripts/07_metrics_report.py | Human-readable metrics report |
| 08 | scripts/08_prepare_sft_data.py | SFT data preparation (training-ready) |
| 09 | scripts/09_lora_finetune.py | Lightweight LoRA fine-tuning |
| 10 | scripts/10_infer_lora.py | Strict inference & hard validation |

Steps 08–10 demonstrate that the generated dataset is **directly usable under strict inference constraints**, not merely theoretically valid.

---

## Documentation Guide

| Document | Description |
|--------|-------------|
| docs/00_design_document.md | Overall system design and rationale |
| docs/01_dataset_schema.md | Unified dataset schema |
| docs/02_domain_map.md | Domain map construction |
| docs/03_pipeline_design.md | Authoritative pipeline design |
| docs/04_demo_and_results.md | Metrics and validation results |


